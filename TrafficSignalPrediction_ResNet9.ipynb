{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport pathlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\nfrom tensorflow.keras.utils import to_categorical\n%matplotlib inline","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir='.../input/gtsrb-german-traffic-sign'\ntrain='../input/gtsrb-german-traffic-sign/Train'\ntest='../input/gtsrb-german-traffic-sign/'\nheight=30\nwidth=30","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes=len(os.listdir(train))\nclasses","execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"43"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_loader(data_dir):\n    images=list()\n    labels=list()\n    for i in range(classes):\n        img_df = os.path.join(data_dir, str(i))\n        for img in os.listdir(img_df):\n            img = load_img(os.path.join(img_df, img),target_size=(30, 30))\n            image = img_to_array(img)\n            images.append(image)\n            labels.append(i)\n    \n    return images, labels\n           \n    \n    ","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images,labels=data_loader(train)","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = to_categorical(labels)","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(np.array(images),labels,test_size=0.4,random_state=42)","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\nfrom tensorflow.keras.models import Sequential\nmodel = Sequential()\n\n# First Convolutional Layer\nmodel.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(height,width,3)))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(rate=0.25))\n\n# Second Convolutional Layer\nmodel.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\nmodel.add(MaxPool2D(pool_size=(3, 3)))\nmodel.add(Dropout(rate=0.25))\n\n# Third Convolutional Layer\nmodel.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n\nmodel.summary()\n","execution_count":62,"outputs":[{"output_type":"stream","text":"Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_12 (Conv2D)           (None, 28, 28, 32)        896       \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 14, 14, 32)        0         \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 14, 14, 32)        0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 12, 12, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_9 (MaxPooling2 (None, 4, 4, 64)          0         \n_________________________________________________________________\ndropout_9 (Dropout)          (None, 4, 4, 64)          0         \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 2, 2, 64)          36928     \n=================================================================\nTotal params: 56,320\nTrainable params: 56,320\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Flattening the layer and adding Dense Layer\nmodel.add(Flatten())\nmodel.add(Dense(units=64, activation='relu'))\nmodel.add(Dense(classes, activation='softmax'))\n\nmodel.summary()","execution_count":63,"outputs":[{"output_type":"stream","text":"Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_12 (Conv2D)           (None, 28, 28, 32)        896       \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 14, 14, 32)        0         \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 14, 14, 32)        0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 12, 12, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_9 (MaxPooling2 (None, 4, 4, 64)          0         \n_________________________________________________________________\ndropout_9 (Dropout)          (None, 4, 4, 64)          0         \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 2, 2, 64)          36928     \n_________________________________________________________________\nflatten_5 (Flatten)          (None, 256)               0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 64)                16448     \n_________________________________________________________________\ndense_9 (Dense)              (None, 43)                2795      \n=================================================================\nTotal params: 75,563\nTrainable params: 75,563\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting the model\nEPOCHS = 35\nhistory = model.fit(x_train, \n                    y_train,\n                    validation_data = (x_test, y_test), \n                    epochs=EPOCHS, \n                    steps_per_epoch=60\n                   )","execution_count":66,"outputs":[{"output_type":"stream","text":"Epoch 1/35\n60/60 [==============================] - 2s 27ms/step - loss: 0.1368 - accuracy: 0.9610 - val_loss: 0.0608 - val_accuracy: 0.9855\nEpoch 2/35\n60/60 [==============================] - 1s 25ms/step - loss: 0.1319 - accuracy: 0.9601 - val_loss: 0.0643 - val_accuracy: 0.9846\nEpoch 3/35\n60/60 [==============================] - 2s 29ms/step - loss: 0.1226 - accuracy: 0.9641 - val_loss: 0.0644 - val_accuracy: 0.9855\nEpoch 4/35\n60/60 [==============================] - 2s 33ms/step - loss: 0.1237 - accuracy: 0.9649 - val_loss: 0.0615 - val_accuracy: 0.9850\nEpoch 5/35\n60/60 [==============================] - 1s 25ms/step - loss: 0.1231 - accuracy: 0.9634 - val_loss: 0.0685 - val_accuracy: 0.9828\nEpoch 6/35\n60/60 [==============================] - 2s 26ms/step - loss: 0.1199 - accuracy: 0.9638 - val_loss: 0.0613 - val_accuracy: 0.9841\nEpoch 7/35\n60/60 [==============================] - 2s 30ms/step - loss: 0.1178 - accuracy: 0.9652 - val_loss: 0.0561 - val_accuracy: 0.9865\nEpoch 8/35\n60/60 [==============================] - 2s 26ms/step - loss: 0.0993 - accuracy: 0.9707 - val_loss: 0.0535 - val_accuracy: 0.9869\nEpoch 9/35\n60/60 [==============================] - 1s 25ms/step - loss: 0.1069 - accuracy: 0.9694 - val_loss: 0.0572 - val_accuracy: 0.9858\nEpoch 10/35\n60/60 [==============================] - 2s 30ms/step - loss: 0.1050 - accuracy: 0.9696 - val_loss: 0.0536 - val_accuracy: 0.9860\nEpoch 11/35\n60/60 [==============================] - 1s 24ms/step - loss: 0.1025 - accuracy: 0.9696 - val_loss: 0.0590 - val_accuracy: 0.9862\nEpoch 12/35\n60/60 [==============================] - 1s 25ms/step - loss: 0.1061 - accuracy: 0.9698 - val_loss: 0.0510 - val_accuracy: 0.9881\nEpoch 13/35\n60/60 [==============================] - 2s 30ms/step - loss: 0.1024 - accuracy: 0.9694 - val_loss: 0.0511 - val_accuracy: 0.9880\nEpoch 14/35\n60/60 [==============================] - 1s 25ms/step - loss: 0.0972 - accuracy: 0.9707 - val_loss: 0.0530 - val_accuracy: 0.9889\nEpoch 15/35\n60/60 [==============================] - 1s 24ms/step - loss: 0.0941 - accuracy: 0.9725 - val_loss: 0.0559 - val_accuracy: 0.9868\nEpoch 16/35\n60/60 [==============================] - 2s 27ms/step - loss: 0.0942 - accuracy: 0.9732 - val_loss: 0.0526 - val_accuracy: 0.9876\nEpoch 17/35\n60/60 [==============================] - 2s 26ms/step - loss: 0.1049 - accuracy: 0.9697 - val_loss: 0.0528 - val_accuracy: 0.9865\nEpoch 18/35\n60/60 [==============================] - 1s 24ms/step - loss: 0.0989 - accuracy: 0.9713 - val_loss: 0.0523 - val_accuracy: 0.9866\nEpoch 19/35\n60/60 [==============================] - 1s 25ms/step - loss: 0.0905 - accuracy: 0.9730 - val_loss: 0.0486 - val_accuracy: 0.9904\nEpoch 20/35\n60/60 [==============================] - 2s 25ms/step - loss: 0.0994 - accuracy: 0.9712 - val_loss: 0.0501 - val_accuracy: 0.9875\nEpoch 21/35\n60/60 [==============================] - 1s 24ms/step - loss: 0.0851 - accuracy: 0.9754 - val_loss: 0.0499 - val_accuracy: 0.9898\nEpoch 22/35\n60/60 [==============================] - 1s 25ms/step - loss: 0.0933 - accuracy: 0.9729 - val_loss: 0.0537 - val_accuracy: 0.9867\nEpoch 23/35\n60/60 [==============================] - 1s 24ms/step - loss: 0.0964 - accuracy: 0.9734 - val_loss: 0.0435 - val_accuracy: 0.9901\nEpoch 24/35\n60/60 [==============================] - 2s 28ms/step - loss: 0.0824 - accuracy: 0.9766 - val_loss: 0.0551 - val_accuracy: 0.9870\nEpoch 25/35\n60/60 [==============================] - 1s 25ms/step - loss: 0.0851 - accuracy: 0.9760 - val_loss: 0.0444 - val_accuracy: 0.9893\nEpoch 26/35\n60/60 [==============================] - 1s 25ms/step - loss: 0.0797 - accuracy: 0.9776 - val_loss: 0.0455 - val_accuracy: 0.9901\nEpoch 27/35\n60/60 [==============================] - 1s 24ms/step - loss: 0.0857 - accuracy: 0.9750 - val_loss: 0.0514 - val_accuracy: 0.9874\nEpoch 28/35\n60/60 [==============================] - 1s 24ms/step - loss: 0.0837 - accuracy: 0.9748 - val_loss: 0.0512 - val_accuracy: 0.9879\nEpoch 29/35\n60/60 [==============================] - 1s 25ms/step - loss: 0.0902 - accuracy: 0.9741 - val_loss: 0.0435 - val_accuracy: 0.9895\nEpoch 30/35\n60/60 [==============================] - 1s 24ms/step - loss: 0.0760 - accuracy: 0.9780 - val_loss: 0.0442 - val_accuracy: 0.9896\nEpoch 31/35\n60/60 [==============================] - 2s 29ms/step - loss: 0.0763 - accuracy: 0.9777 - val_loss: 0.0567 - val_accuracy: 0.9871\nEpoch 32/35\n60/60 [==============================] - 2s 25ms/step - loss: 0.0771 - accuracy: 0.9779 - val_loss: 0.0421 - val_accuracy: 0.9902\nEpoch 33/35\n60/60 [==============================] - 2s 29ms/step - loss: 0.0775 - accuracy: 0.9779 - val_loss: 0.0489 - val_accuracy: 0.9874\nEpoch 34/35\n60/60 [==============================] - 2s 25ms/step - loss: 0.0712 - accuracy: 0.9790 - val_loss: 0.0441 - val_accuracy: 0.9898\nEpoch 35/35\n60/60 [==============================] - 1s 25ms/step - loss: 0.0780 - accuracy: 0.9776 - val_loss: 0.0461 - val_accuracy: 0.9888\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = model.evaluate(x_test, y_test)","execution_count":67,"outputs":[{"output_type":"stream","text":"491/491 [==============================] - 1s 3ms/step - loss: 0.0461 - accuracy: 0.9888\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nimport pandas as pd\n\nY_test = pd.read_csv(test + 'Test.csv')\ntest_labels = Y_test[\"ClassId\"].values\nY_test = Y_test[\"Path\"].values\n\noutput = list()\nfor img in Y_test:\n    image = load_img(os.path.join(test,img), target_size=(30, 30))\n    output.append(np.array(image))\n\nX_test=np.array(output)\npred = model.predict_classes(X_test)\n\n#Accuracy with the test data\nprint('Test Data accuracy: ',accuracy_score(test_labels, pred)*100)","execution_count":78,"outputs":[{"output_type":"stream","text":"Test Data accuracy:  93.83214568487728\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}